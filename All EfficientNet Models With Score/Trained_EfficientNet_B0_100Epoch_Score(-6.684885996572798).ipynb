{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.9 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.12.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (21.3)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (4.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (14.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (3.12.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (0.2.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (47.3.1.post20200622)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (0.27.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (2.10.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (2.9.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorflow-gpu==2.9) (1.27.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from packaging->tensorflow-gpu==2.9) (3.0.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu==2.9) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.6.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.1.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.14.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.2.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (2.1.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu==2.9) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow-gpu==2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python==4.5.1.48 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from opencv-python==4.5.1.48) (1.21.6)\n",
      "Requirement already satisfied: pandas==1.2.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from pandas==1.2.1) (1.21.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from pandas==1.2.1) (2022.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from pandas==1.2.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from python-dateutil>=2.7.3->pandas==1.2.1) (1.15.0)\n",
      "Requirement already satisfied: Pillow==8.1.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (8.1.0)\n",
      "Requirement already satisfied: pydicom==2.1.2 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: scikit-learn==0.24.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-learn==0.24.1) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-learn==0.24.1) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-learn==0.24.1) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-learn==0.24.1) (3.1.0)\n",
      "Requirement already satisfied: scipy==1.6.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scipy==1.6.0) (1.21.6)\n",
      "Requirement already satisfied: tqdm==4.56.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (4.56.0)\n",
      "Requirement already satisfied: tikzplotlib in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tikzplotlib) (8.1.0)\n",
      "Requirement already satisfied: webcolors in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tikzplotlib) (1.12)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from tikzplotlib) (3.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from tikzplotlib) (1.21.6)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib>=1.4.0->tikzplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib>=1.4.0->tikzplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=1.4.0->tikzplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=1.4.0->tikzplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->tikzplotlib) (1.15.0)\n",
      "Requirement already satisfied: efficientnet in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from efficientnet) (0.18.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->efficientnet) (2.5.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->efficientnet) (2021.4.8)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-image->efficientnet) (8.1.0)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->efficientnet) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-image->efficientnet) (1.21.6)\n",
      "Requirement already satisfied: imageio>=2.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from scikit-image->efficientnet) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from scikit-image->efficientnet) (1.6.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.15.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: typing_extensions; python_version < \"3.8\" in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from seaborn) (4.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from seaborn) (3.4.2)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from seaborn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from seaborn) (1.21.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=3.1->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib>=3.1->seaborn) (8.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from matplotlib>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib>=3.1->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.4)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\keras-gpu\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.1->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python==4.5.1.48\n",
    "# !pip install pandas==1.2.1\n",
    "# !pip install Pillow==8.1.0\n",
    "# !pip install pydicom==2.1.2\n",
    "# !pip install scikit-learn==0.24.1\n",
    "# !pip install scipy==1.6.0\n",
    "# !pip install tqdm==4.56.0\n",
    "# !pip install tikzplotlib\n",
    "# !pip install efficientnet\n",
    "# !pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import tikzplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.145377828922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.8775766716943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \" return an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddea15deb2e49868489f556a7bc2a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \" read DICOM dataset and return resize images of size (512,512,3)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    resized_image = np.stack((resized_image,)*3, axis = -1)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'./Dataset//train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'./Dataset//train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        #x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights='imagenet',include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights=None,include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False),\n",
    "        #'RNet50': resnet50.ResNet50(input_shape=shape,weights=None,include_top=False),\n",
    "        #'V16': vgg16.VGG16(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 3), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_model(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " efficientnet-b0 (Functional)   (None, 16, 16, 1280  4049564     ['input_21[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " input_30 (InputLayer)          [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 1280)        0           ['efficientnet-b0[0][0]']        \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " gaussian_noise_2 (GaussianNois  (None, 4)           0           ['input_30[0][0]']               \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 1284)         0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'gaussian_noise_2[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1284)         0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            1285        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,050,849\n",
      "Trainable params: 4,008,833\n",
      "Non-trainable params: 42,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b0'\n",
    "base_model = build_model(shape=(512, 512, 3), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "SAVE_BEST = True\n",
    "tr_p, vl_p = train_test_split(P, shuffle=True, train_size= 0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183CBC0A4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183CBC0A4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4661WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183BC3B6318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183BC3B6318> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 6.18188, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 69s 2s/step - loss: 4.4661 - val_loss: 6.1819 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9733\n",
      "Epoch 2: val_loss improved from 6.18188 to 4.33449, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.9733 - val_loss: 4.3345 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9008\n",
      "Epoch 3: val_loss improved from 4.33449 to 3.94590, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 3.9008 - val_loss: 3.9459 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9756\n",
      "Epoch 4: val_loss did not improve from 3.94590\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.9756 - val_loss: 8.2600 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1419\n",
      "Epoch 5: val_loss improved from 3.94590 to 3.79528, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 5.1419 - val_loss: 3.7953 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8130\n",
      "Epoch 6: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.8130 - val_loss: 6.7818 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9573\n",
      "Epoch 7: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 60s 2s/step - loss: 3.9573 - val_loss: 5.1467 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6557\n",
      "Epoch 8: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.6557 - val_loss: 5.1515 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2227\n",
      "Epoch 9: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2227 - val_loss: 4.8667 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1091\n",
      "Epoch 10: val_loss did not improve from 3.79528\n",
      "\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.1091 - val_loss: 4.7665 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0948\n",
      "Epoch 11: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.0948 - val_loss: 4.7452 - lr: 5.0000e-04\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1111\n",
      "Epoch 12: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.1111 - val_loss: 4.6978 - lr: 5.0000e-04\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1493\n",
      "Epoch 13: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.1493 - val_loss: 4.3359 - lr: 5.0000e-04\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8274\n",
      "Epoch 14: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.8274 - val_loss: 3.9297 - lr: 5.0000e-04\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9907\n",
      "Epoch 15: val_loss did not improve from 3.79528\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.9907 - val_loss: 4.2183 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6425\n",
      "Epoch 16: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.6425 - val_loss: 4.7804 - lr: 2.5000e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4306\n",
      "Epoch 17: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4306 - val_loss: 4.0183 - lr: 2.5000e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9618\n",
      "Epoch 18: val_loss did not improve from 3.79528\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.9618 - val_loss: 4.2975 - lr: 2.5000e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.4651\n",
      "Epoch 19: val_loss improved from 3.79528 to 3.53080, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 5.4651 - val_loss: 3.5308 - lr: 2.5000e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4399\n",
      "Epoch 20: val_loss did not improve from 3.53080\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4399 - val_loss: 4.3772 - lr: 2.5000e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4560\n",
      "Epoch 21: val_loss did not improve from 3.53080\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4560 - val_loss: 4.2981 - lr: 2.5000e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1944\n",
      "Epoch 22: val_loss improved from 3.53080 to 3.52708, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.1944 - val_loss: 3.5271 - lr: 2.5000e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0719\n",
      "Epoch 23: val_loss did not improve from 3.52708\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.0719 - val_loss: 4.3056 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2085\n",
      "Epoch 24: val_loss did not improve from 3.52708\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2085 - val_loss: 4.2385 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6664\n",
      "Epoch 25: val_loss did not improve from 3.52708\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.6664 - val_loss: 4.6919 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6902\n",
      "Epoch 26: val_loss did not improve from 3.52708\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.6902 - val_loss: 4.0735 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5235\n",
      "Epoch 27: val_loss did not improve from 3.52708\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.5235 - val_loss: 3.8812 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0355\n",
      "Epoch 28: val_loss did not improve from 3.52708\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.0355 - val_loss: 3.8529 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4517\n",
      "Epoch 29: val_loss improved from 3.52708 to 3.13679, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.4517 - val_loss: 3.1368 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6991\n",
      "Epoch 30: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.6991 - val_loss: 3.7867 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.1597\n",
      "Epoch 31: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.1597 - val_loss: 4.4856 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0696\n",
      "Epoch 32: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0696 - val_loss: 4.1002 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3506\n",
      "Epoch 33: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.3506 - val_loss: 3.5852 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7992\n",
      "Epoch 34: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.7992 - val_loss: 3.6253 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7178\n",
      "Epoch 35: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.7178 - val_loss: 4.7940 - lr: 6.2500e-05\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8158\n",
      "Epoch 36: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.8158 - val_loss: 3.9432 - lr: 6.2500e-05\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2036\n",
      "Epoch 37: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2036 - val_loss: 3.8927 - lr: 6.2500e-05\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0370\n",
      "Epoch 38: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0370 - val_loss: 3.3982 - lr: 6.2500e-05\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0234\n",
      "Epoch 39: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 5.0234 - val_loss: 4.5339 - lr: 6.2500e-05\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5380\n",
      "Epoch 40: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.5380 - val_loss: 3.8066 - lr: 3.1250e-05\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2446\n",
      "Epoch 41: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2446 - val_loss: 3.7402 - lr: 3.1250e-05\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4988\n",
      "Epoch 42: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4988 - val_loss: 3.5689 - lr: 3.1250e-05\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2259\n",
      "Epoch 43: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2259 - val_loss: 3.7207 - lr: 3.1250e-05\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4894\n",
      "Epoch 44: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4894 - val_loss: 3.3489 - lr: 3.1250e-05\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1410\n",
      "Epoch 45: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1410 - val_loss: 4.2874 - lr: 1.5625e-05\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8271\n",
      "Epoch 46: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.8271 - val_loss: 3.6423 - lr: 1.5625e-05\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7874\n",
      "Epoch 47: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.7874 - val_loss: 3.8073 - lr: 1.5625e-05\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1622\n",
      "Epoch 48: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1622 - val_loss: 3.6274 - lr: 1.5625e-05\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9993\n",
      "Epoch 49: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.9993 - val_loss: 4.3255 - lr: 1.5625e-05\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7006\n",
      "Epoch 50: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.7006 - val_loss: 4.3166 - lr: 7.8125e-06\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6978\n",
      "Epoch 51: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.6978 - val_loss: 3.4828 - lr: 7.8125e-06\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7621\n",
      "Epoch 52: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.7621 - val_loss: 4.3843 - lr: 7.8125e-06\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6029\n",
      "Epoch 53: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.6029 - val_loss: 4.5367 - lr: 7.8125e-06\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7246\n",
      "Epoch 54: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.7246 - val_loss: 3.6721 - lr: 7.8125e-06\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1146\n",
      "Epoch 55: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1146 - val_loss: 4.0419 - lr: 3.9063e-06\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2619\n",
      "Epoch 56: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2619 - val_loss: 3.8609 - lr: 3.9063e-06\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2444\n",
      "Epoch 57: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2444 - val_loss: 3.9398 - lr: 3.9063e-06\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1247\n",
      "Epoch 58: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1247 - val_loss: 3.4202 - lr: 3.9063e-06\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9809\n",
      "Epoch 59: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.9809 - val_loss: 4.1710 - lr: 3.9063e-06\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 4.1769\n",
      "Epoch 60: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1769 - val_loss: 3.8829 - lr: 1.9531e-06\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8140\n",
      "Epoch 61: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.8140 - val_loss: 3.9208 - lr: 1.9531e-06\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0492\n",
      "Epoch 62: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0492 - val_loss: 3.6700 - lr: 1.9531e-06\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7525\n",
      "Epoch 63: val_loss did not improve from 3.13679\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.7525 - val_loss: 3.4985 - lr: 1.9531e-06\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8141\n",
      "Epoch 64: val_loss did not improve from 3.13679\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.8141 - val_loss: 3.2470 - lr: 1.9531e-06\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9375\n",
      "Epoch 65: val_loss improved from 3.13679 to 2.97409, saving model to b0_100_epochs.h5\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.9375 - val_loss: 2.9741 - lr: 9.7656e-07\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7655\n",
      "Epoch 66: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.7655 - val_loss: 3.6843 - lr: 9.7656e-07\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2411\n",
      "Epoch 67: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2411 - val_loss: 3.4063 - lr: 9.7656e-07\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9879\n",
      "Epoch 68: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.9879 - val_loss: 3.6102 - lr: 9.7656e-07\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9404\n",
      "Epoch 69: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.9404 - val_loss: 4.2386 - lr: 9.7656e-07\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0226\n",
      "Epoch 70: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0226 - val_loss: 3.8430 - lr: 9.7656e-07\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2950\n",
      "Epoch 71: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2950 - val_loss: 3.8777 - lr: 4.8828e-07\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8598\n",
      "Epoch 72: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.8598 - val_loss: 3.6110 - lr: 4.8828e-07\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4219\n",
      "Epoch 73: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4219 - val_loss: 4.3813 - lr: 4.8828e-07\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4309\n",
      "Epoch 74: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.4309 - val_loss: 4.5957 - lr: 4.8828e-07\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2141\n",
      "Epoch 75: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.2141 - val_loss: 4.2301 - lr: 4.8828e-07\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1065\n",
      "Epoch 76: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1065 - val_loss: 3.7644 - lr: 2.4414e-07\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7306\n",
      "Epoch 77: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.7306 - val_loss: 3.4218 - lr: 2.4414e-07\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2989\n",
      "Epoch 78: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2989 - val_loss: 4.0614 - lr: 2.4414e-07\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8934\n",
      "Epoch 79: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.8934 - val_loss: 4.1140 - lr: 2.4414e-07\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2540\n",
      "Epoch 80: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2540 - val_loss: 3.1714 - lr: 2.4414e-07\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8586\n",
      "Epoch 81: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.8586 - val_loss: 4.1312 - lr: 1.2207e-07\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9359\n",
      "Epoch 82: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.9359 - val_loss: 3.9091 - lr: 1.2207e-07\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2821\n",
      "Epoch 83: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2821 - val_loss: 3.5631 - lr: 1.2207e-07\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0957\n",
      "Epoch 84: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0957 - val_loss: 3.6792 - lr: 1.2207e-07\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7140\n",
      "Epoch 85: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.7140 - val_loss: 3.3116 - lr: 1.2207e-07\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6705\n",
      "Epoch 86: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.6705 - val_loss: 4.3555 - lr: 6.1035e-08\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5168\n",
      "Epoch 87: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.5168 - val_loss: 4.2200 - lr: 6.1035e-08\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5280\n",
      "Epoch 88: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.5280 - val_loss: 4.1964 - lr: 6.1035e-08\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2493\n",
      "Epoch 89: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2493 - val_loss: 3.9441 - lr: 6.1035e-08\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7643\n",
      "Epoch 90: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.7643 - val_loss: 3.9701 - lr: 6.1035e-08\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5868\n",
      "Epoch 91: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.5868 - val_loss: 4.0499 - lr: 3.0518e-08\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1187\n",
      "Epoch 92: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.1187 - val_loss: 3.6642 - lr: 3.0518e-08\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2737\n",
      "Epoch 93: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2737 - val_loss: 3.5454 - lr: 3.0518e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8587\n",
      "Epoch 94: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 60s 2s/step - loss: 4.8587 - val_loss: 4.0004 - lr: 3.0518e-08\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0038\n",
      "Epoch 95: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0038 - val_loss: 4.8065 - lr: 3.0518e-08\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2755\n",
      "Epoch 96: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.2755 - val_loss: 3.9579 - lr: 1.5259e-08\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0716\n",
      "Epoch 97: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 4.0716 - val_loss: 3.5490 - lr: 1.5259e-08\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7535\n",
      "Epoch 98: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.7535 - val_loss: 3.7155 - lr: 1.5259e-08\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6812\n",
      "Epoch 99: val_loss did not improve from 2.97409\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.6812 - val_loss: 3.1415 - lr: 1.5259e-08\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6524\n",
      "Epoch 100: val_loss did not improve from 2.97409\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "32/32 [==============================] - 59s 2s/step - loss: 3.6524 - val_loss: 4.1030 - lr: 1.5259e-08\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=tr_p, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = './Saved_Models/EffNet_b0_history_100_epoch_imagenet.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = './Saved_Models/EffNet_b0_history_100_epoch_imagenet.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = './Dataset/train/B0'\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(result_dir + 'b0_100_epoch_loss_imagenet.png')\n",
    "plt.savefig(result_dir + 'b0_100_epoch_loss_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_100_epoch_loss_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.85):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'bo', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b0_100_epoch_loss_smooth_imagenet.png')\n",
    "plt.savefig(result_dir + 'b0_100_epoch_loss_smooth_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b0_100_epoch_loss_smooth_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(fvc_true, fvc_pred, sigma):\n",
    "    sigma_clip = np.maximum(sigma, 70)\n",
    "    delta = np.abs(fvc_true - fvc_pred)\n",
    "    delta = np.minimum(delta, 1000)\n",
    "    sq2 = np.sqrt(2)\n",
    "    metric = (delta / sigma_clip)*sq2 + np.log(sigma_clip* sq2)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db69c51be27453c82034dd041a0a139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C657D4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C657D4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 2s 110ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 874ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 20s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 2s 319ms/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 34s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.7164727780412115\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "2/2 [==============================] - 2s 111ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 1s 865ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "10/10 [==============================] - 21s 2s/step\n",
      "9/9 [==============================] - 20s 2s/step\n",
      "2/2 [==============================] - 5s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 3s 340ms/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 33s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.721189284963062\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "13/13 [==============================] - 27s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "2/2 [==============================] - 2s 113ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 20s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 855ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 21s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 3s 320ms/step\n",
      "13/13 [==============================] - 30s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "2/2 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 10s 2s/step\n",
      "16/16 [==============================] - 34s 2s/step\n",
      "13/13 [==============================] - 30s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 7s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 23s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.725443473227239\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "2/2 [==============================] - 2s 125ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 866ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 21s 2s/step\n",
      "9/9 [==============================] - 22s 2s/step\n",
      "2/2 [==============================] - 5s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 2s 323ms/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 34s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.727688457655034\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 2s 116ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 824ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 20s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 2s 318ms/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 33s 2s/step\n",
      "13/13 [==============================] - 27s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.73096424493282\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "13/13 [==============================] - 27s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 2s 118ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 20s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 2s 318ms/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 34s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.73547226489897\n",
      "16/16 [==============================] - 36s 2s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "13/13 [==============================] - 34s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "2/2 [==============================] - 2s 108ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 863ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 21s 2s/step\n",
      "9/9 [==============================] - 20s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 2s 319ms/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "2/2 [==============================] - 3s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 38s 2s/step\n",
      "13/13 [==============================] - 34s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.7410657042624145\n",
      "16/16 [==============================] - 37s 2s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "13/13 [==============================] - 34s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "9/9 [==============================] - 22s 2s/step\n",
      "2/2 [==============================] - 3s 122ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 21s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 1s 869ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "10/10 [==============================] - 22s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 3s 318ms/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "2/2 [==============================] - 4s 1s/step\n",
      "4/4 [==============================] - 8s 2s/step\n",
      "16/16 [==============================] - 34s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 19s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.7477249775504164\n",
      "16/16 [==============================] - 35s 2s/step\n",
      "4/4 [==============================] - 7s 2s/step\n",
      "13/13 [==============================] - 29s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 18s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 2s 112ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 19s 2s/step\n",
      "3/3 [==============================] - 5s 1s/step\n",
      "1/1 [==============================] - 1s 856ms/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "10/10 [==============================] - 21s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "2/2 [==============================] - 3s 319ms/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "4/4 [==============================] - 10s 3s/step\n",
      "16/16 [==============================] - 34s 2s/step\n",
      "13/13 [==============================] - 28s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "3/3 [==============================] - 6s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9/9 [==============================] - 18s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6.754960330708776\n"
     ]
    }
   ],
   "source": [
    "metric = []\n",
    "for q in tqdm(range(1, 10)):\n",
    "    m = []\n",
    "    for p in vl_p:\n",
    "        x = [] \n",
    "        tab = [] \n",
    "        \n",
    "        if p in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n",
    "            continue\n",
    "        for i in os.listdir(f'./Dataset/train/{p}/'):\n",
    "            x.append(get_img(f'./Dataset/train/{p}/{i}')) \n",
    "            tab.append(get_tab(train.loc[train.Patient == p, :])) \n",
    "        tab = np.array(tab) \n",
    "    \n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        _a = model.predict([x, tab]) \n",
    "        a = np.quantile(_a, q / 10)\n",
    "        \n",
    "        percent_true = train.Percent.values[train.Patient == p]\n",
    "        fvc_true = train.FVC.values[train.Patient == p]\n",
    "        weeks_true = train.Weeks.values[train.Patient == p]\n",
    "        \n",
    "        fvc = a * (weeks_true - weeks_true[0]) + fvc_true[0]\n",
    "        percent = percent_true[0] - a * abs(weeks_true - weeks_true[0])\n",
    "        m.append(score(fvc_true, fvc, percent))\n",
    "    print(np.mean(m))\n",
    "    metric.append(np.mean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (np.argmin(metric) + 1)/ 2\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week   FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  2000         100\n",
       "1  ID00421637202311550012437_-12  2000         100\n",
       "2  ID00422637202311677017371_-12  2000         100\n",
       "3  ID00423637202312137826377_-12  2000         100\n",
       "4  ID00426637202313170790466_-12  2000         100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('./Dataset//sample_submission.csv') \n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>6</td>\n",
       "      <td>3020</td>\n",
       "      <td>70.186855</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>82.045291</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371</td>\n",
       "      <td>6</td>\n",
       "      <td>1930</td>\n",
       "      <td>76.672493</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377</td>\n",
       "      <td>17</td>\n",
       "      <td>3294</td>\n",
       "      <td>79.258903</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>0</td>\n",
       "      <td>2925</td>\n",
       "      <td>71.824968</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00419637202311204720264      6  3020  70.186855   73  Male     Ex-smoker\n",
       "1  ID00421637202311550012437     15  2739  82.045291   68  Male     Ex-smoker\n",
       "2  ID00422637202311677017371      6  1930  76.672493   73  Male     Ex-smoker\n",
       "3  ID00423637202312137826377     17  3294  79.258903   72  Male     Ex-smoker\n",
       "4  ID00426637202313170790466      0  2925  71.824968   73  Male  Never smoked"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./Dataset//test.csv') \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "2/2 [==============================] - 4s 2s/step\n",
      "15/15 [==============================] - 32s 2s/step\n",
      "10/10 [==============================] - 21s 2s/step\n",
      "13/13 [==============================] - 27s 2s/step\n"
     ]
    }
   ],
   "source": [
    "A_test, B_test, P_test, W, FVC, STD, WEEK = {},{},{},{},{},{},{} \n",
    "\n",
    "for p in test.Patient.unique():\n",
    "    x = [] \n",
    "    tab = [] \n",
    "    for i in os.listdir(f'./Dataset//test/{p}/'):\n",
    "        x.append(get_img(f'./Dataset//test/{p}/{i}')) \n",
    "        tab.append(get_tab(test.loc[test.Patient == p, :])) \n",
    "    tab = np.array(tab) \n",
    "            \n",
    "    x = np.expand_dims(x, axis=-1) \n",
    "    _a = model.predict([x, tab]) \n",
    "    a = np.quantile(_a, q)\n",
    "    A_test[p] = a\n",
    "    B_test[p] = test.FVC.values[test.Patient == p] - a*test.Weeks.values[test.Patient == p]\n",
    "    P_test[p] = test.Percent.values[test.Patient == p] \n",
    "    WEEK[p] = test.Weeks.values[test.Patient == p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sub.Patient_Week.values:\n",
    "    p, w = k.split('_')\n",
    "    w = int(w) \n",
    "    \n",
    "    fvc = A_test[p] * w + B_test[p]\n",
    "    sub.loc[sub.Patient_Week == k, 'FVC'] = fvc\n",
    "    sub.loc[sub.Patient_Week == k, 'Confidence'] = (\n",
    "        P_test[p] - A_test[p] * abs(WEEK[p] - w) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>3140.803420</td>\n",
       "      <td>190.990275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2812.877061</td>\n",
       "      <td>155.922353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>1998.844945</td>\n",
       "      <td>145.517439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>3495.315398</td>\n",
       "      <td>280.574301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2958.536259</td>\n",
       "      <td>105.361227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week          FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  3140.803420  190.990275\n",
       "1  ID00421637202311550012437_-12  2812.877061  155.922353\n",
       "2  ID00422637202311677017371_-12  1998.844945  145.517439\n",
       "3  ID00423637202312137826377_-12  3495.315398  280.574301\n",
       "4  ID00426637202313170790466_-12  2958.536259  105.361227"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add infos\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"./Dataset//\"\n",
    "BATCH_SIZE=128\n",
    "\n",
    "tr = pd.read_csv(f\"{ROOT}/train.csv\")\n",
    "tr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "chunk = pd.read_csv(f\"{ROOT}/test.csv\")\n",
    "\n",
    "print(\"add infos\")\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "sub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\n",
    "sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['WHERE'] = 'train'\n",
    "chunk['WHERE'] = 'val'\n",
    "sub['WHERE'] = 'test'\n",
    "data = tr.append([chunk, sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1535, 8) (5, 8) (730, 10) (2270, 10)\n",
      "176 5 5 176\n"
     ]
    }
   ],
   "source": [
    "print(tr.shape, chunk.shape, sub.shape, data.shape)\n",
    "print(tr.Patient.nunique(), chunk.Patient.nunique(), sub.Patient.nunique(), \n",
    "      data.Patient.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_week'] = data['Weeks']\n",
    "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
    "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data.loc[data.Weeks == data.min_week]\n",
    "base = base[['Patient','FVC']].copy()\n",
    "base.columns = ['Patient','min_FVC']\n",
    "base['nb'] = 1\n",
    "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
    "base = base[base.nb==1]\n",
    "base.drop('nb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(base, on='Patient', how='left')\n",
    "data['base_week'] = data['Weeks'] - data['min_week']\n",
    "del base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['Sex','SmokingStatus'] #,'Age'\n",
    "FE = []\n",
    "for col in COLS:\n",
    "    for mod in data[col].unique():\n",
    "        FE.append(mod)\n",
    "        data[mod] = (data[col] == mod).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
    "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
    "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
    "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
    "FE += ['age','percent','week','BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = data.loc[data.WHERE=='train']\n",
    "chunk = data.loc[data.WHERE=='val']\n",
    "sub = data.loc[data.WHERE=='test']\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14748\\1446129434.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "tr.shape, chunk.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return K.mean(metric)\n",
    "\n",
    "def qloss(y_true, y_pred):\n",
    "    qs = [0.2, 0.50, 0.8]\n",
    "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "    e = y_true - y_pred\n",
    "    v = tf.maximum(q*e, (q-1)*e)\n",
    "    return K.mean(v)\n",
    "\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def laplace_log_likelihood(actual_fvc, predicted_fvc, confidence, return_values = False):\n",
    "    \"\"\"\n",
    "    Calculates the modified Laplace Log Likelihood score for this competition.\n",
    "    \"\"\"\n",
    "    sd_clipped = np.maximum(confidence, 70)\n",
    "    delta = np.minimum(np.abs(actual_fvc - predicted_fvc), 1000)\n",
    "    metric = - np.sqrt(2) * delta / sd_clipped - np.log(np.sqrt(2) * sd_clipped)\n",
    "\n",
    "    if return_values:\n",
    "        return metric\n",
    "    else:\n",
    "        return np.mean(metric)\n",
    "\n",
    "def make_model(nh):\n",
    "    z = L.Input((nh,), name=\"Patient\")\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d1\")(z)\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d2\")(x)\n",
    "    p1 = L.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
    "    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
    "    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                     name=\"preds\")([p1, p2])\n",
    "    \n",
    "    model = M.Model(z, preds, name=\"CNN\")\n",
    "    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n",
    "    model.compile(loss=mloss(0.8), optimizer=tf.keras.optimizers.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), metrics=[score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET TRAINING DATA AND TARGET VALUE\n",
    "\n",
    "# get target value\n",
    "y  = tr['FVC'].values\n",
    "\n",
    "# get training & test data\n",
    "X_train = tr[FE].values\n",
    "X_test = sub[FE].values\n",
    "\n",
    "\n",
    "nh = X_train.shape[1]\n",
    "\n",
    "# instantiate target arrays\n",
    "train_preds = np.zeros((X_train.shape[0], 3))\n",
    "test_preds = np.zeros((X_test.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Patient (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " d1 (Dense)                     (None, 100)          1000        ['Patient[0][0]']                \n",
      "                                                                                                  \n",
      " d2 (Dense)                     (None, 100)          10100       ['d1[0][0]']                     \n",
      "                                                                                                  \n",
      " p1 (Dense)                     (None, 3)            303         ['d2[0][0]']                     \n",
      "                                                                                                  \n",
      " p2 (Dense)                     (None, 3)            303         ['d2[0][0]']                     \n",
      "                                                                                                  \n",
      " preds (Lambda)                 (None, 3)            0           ['p1[0][0]',                     \n",
      "                                                                  'p2[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,706\n",
      "Trainable params: 11,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "11706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "net = make_model(nh)\n",
    "print(net.summary())\n",
    "print(net.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2315., 2214., 2061., ..., 2908., 2975., 2774.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183DE98CEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183DE98CEE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183DE98C948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183DE98C948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function score at 0x00000183C1463F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function score at 0x00000183C1463F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C1C215E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C1C215E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "train [42.30588912963867, 6.542652130126953]\n",
      "val [41.27309799194336, 6.550489902496338]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C1DC7678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C1DC7678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "predict test...\n",
      "FOLD 2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C1DC7DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C1DC7DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C1ED9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C1ED9558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C160F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C160F558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "train [36.37632751464844, 6.418815612792969]\n",
      "val [55.70987319946289, 6.8531718254089355]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C3520F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C3520F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict test...\n",
      "FOLD 3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C35CE5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C35CE5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C3490E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C3490E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C46BE5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C46BE5E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "train [41.11624526977539, 6.52423095703125]\n",
      "val [47.95667266845703, 6.933601379394531]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C4AC9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C4AC9948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "predict test...\n",
      "FOLD 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C4E21F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C4E21F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C4E21798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C4E21798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C51A59D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183C51A59D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "train [40.50454330444336, 6.532534122467041]\n",
      "val [46.62852096557617, 6.633406162261963]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C55ED438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C55ED438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "predict test...\n",
      "FOLD 5\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C55D4678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000183C55D4678> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C55D4438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function mloss.<locals>.loss at 0x00000183C55D4438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183CDFC7DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000183CDFC7DC8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "train [41.16156768798828, 6.549253940582275]\n",
      "val [46.96144104003906, 6.6749796867370605]\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C11305E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000183C11305E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "predict test...\n"
     ]
    }
   ],
   "source": [
    "model_cnt = 1\n",
    "# instantiate target arrays\n",
    "globals()['train_preds_{}'.format(model_cnt)] = np.zeros((X_train.shape[0], 3))\n",
    "globals()['test_preds_{}'.format(model_cnt)] = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "NFOLD = 5\n",
    "gkf = GroupKFold(n_splits=NFOLD)\n",
    "groups = tr['Patient'].values\n",
    "\n",
    "cnt = 0\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE=128\n",
    "\n",
    "for tr_idx, val_idx in gkf.split(X_train,y, groups):\n",
    "    cnt += 1\n",
    "    print(f\"FOLD {cnt}\")\n",
    "    net = make_model(nh)\n",
    "    net.fit(X_train[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(X_train[val_idx], y[val_idx]), verbose=0) #\n",
    "    print(\"train\", net.evaluate(X_train[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "    print(\"val\", net.evaluate(X_train[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "        #print(\"predict val...\")\n",
    "    globals()['train_preds_{}'.format(model_cnt)][val_idx] = net.predict(X_train[val_idx], batch_size=BATCH_SIZE, verbose=0)\n",
    "    print(\"predict test...\")\n",
    "    globals()['test_preds_{}'.format(model_cnt)] += net.predict(X_test, batch_size=BATCH_SIZE, verbose=0) / NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score:  -6.684885996572798\n"
     ]
    }
   ],
   "source": [
    "predicted_fvc = globals()['train_preds_{}'.format(model_cnt)][:,1]\n",
    "confidence = globals()['train_preds_{}'.format(model_cnt)][:,2]-globals()['train_preds_{}'.format(model_cnt)][:,0]\n",
    "model_score = laplace_log_likelihood(actual_fvc = y, predicted_fvc = predicted_fvc, confidence = confidence,\n",
    "                       return_values = False)\n",
    "print('Overall Score: ', model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

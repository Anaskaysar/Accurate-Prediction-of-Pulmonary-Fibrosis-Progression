{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python==4.5.1.48\n",
    "# !pip install pandas==1.2.1\n",
    "# !pip install Pillow==8.1.0\n",
    "# !pip install pydicom==2.1.2\n",
    "# !pip install scikit-learn==0.24.1\n",
    "# !pip install scipy==1.6.0\n",
    "# !pip install tqdm==4.56.0\n",
    "# !pip install tikzplotlib\n",
    "# !pip install efficientnet\n",
    "# !pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pydicom\n",
    "import tikzplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, GlobalAveragePooling2D, GaussianNoise, \n",
    "    Add, Conv2D, AveragePooling2D, LeakyReLU, Concatenate \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>-4</td>\n",
       "      <td>2315</td>\n",
       "      <td>58.253649</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>5</td>\n",
       "      <td>2214</td>\n",
       "      <td>55.712129</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>7</td>\n",
       "      <td>2061</td>\n",
       "      <td>51.862104</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>9</td>\n",
       "      <td>2144</td>\n",
       "      <td>53.950679</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00007637202177411956430</td>\n",
       "      <td>11</td>\n",
       "      <td>2069</td>\n",
       "      <td>52.063412</td>\n",
       "      <td>79</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00007637202177411956430     -4  2315  58.253649   79  Male     Ex-smoker\n",
       "1  ID00007637202177411956430      5  2214  55.712129   79  Male     Ex-smoker\n",
       "2  ID00007637202177411956430      7  2061  51.862104   79  Male     Ex-smoker\n",
       "3  ID00007637202177411956430      9  2144  53.950679   79  Male     Ex-smoker\n",
       "4  ID00007637202177411956430     11  2069  52.063412   79  Male     Ex-smoker"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153.145377828922"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.8775766716943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Percent'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ex-smoker', 'Never smoked', 'Currently smokes'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.SmokingStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tab(df):\n",
    "    \" return an array which contains each patient normalized age, sex and smoking status\"\n",
    "    vector = [(df.Age.values[0] - 30) / 30] \n",
    "    \n",
    "    if df.Sex.values[0].lower() == 'male':\n",
    "       vector.append(0)\n",
    "    else:\n",
    "       vector.append(1)\n",
    "    \n",
    "    if df.SmokingStatus.values[0] == 'Never smoked':\n",
    "        vector.extend([0,0])\n",
    "    elif df.SmokingStatus.values[0] == 'Ex-smoker':\n",
    "        vector.extend([1,1])\n",
    "    elif df.SmokingStatus.values[0] == 'Currently smokes':\n",
    "        vector.extend([0,1])\n",
    "    else:\n",
    "        vector.extend([1,0])\n",
    "    return np.array(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76efec9b48f94713b0c9d2af5aa6b958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\keras-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "A = {} \n",
    "TAB = {} \n",
    "P = [] \n",
    "for i, p in tqdm(enumerate(train.Patient.unique())): # i index, p patient id\n",
    "    sub = train.loc[train.Patient == p, :] # find all data (weeks, FVC, Percent, Age, Sex, SmokingStatus) of a unique patient\n",
    "    fvc = sub.FVC.values # fvc values of the patient during the follow-up\n",
    "    weeks = sub.Weeks.values # follow-up weeks\n",
    "    c = np.vstack([weeks, np.ones(len(weeks))]).T # create an array by the follow-up weeks of shape(len(weeks),2)\n",
    "    a, b = np.linalg.lstsq(c, fvc)[0] # least-square sol, a=gradient matrix, b=right hand matrix \n",
    "    \n",
    "    A[p] = a\n",
    "    TAB[p] = get_tab(sub)\n",
    "    P.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(path):\n",
    "    \" read DICOM dataset and return resize images of size (512,512,3)\"\n",
    "    d = pydicom.dcmread(path) # read and parse the CT scan images (in DICOM format)\n",
    "    resized_image = cv2.resize((d.pixel_array - d.RescaleIntercept) / (d.RescaleSlope * 1000), (512,512))\n",
    "    resized_image = np.stack((resized_image,)*3, axis = -1)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IGenerator(Sequence):\n",
    "    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "    def __init__(self, keys, a, tab, batch_size):\n",
    "        \"key=patient, a=gradient matrix, tab=a particular patient's data\"\n",
    "        self.keys = [k for k in keys if k not in self.BAD_ID]\n",
    "        self.a = a\n",
    "        self.tab = tab\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_data = {}\n",
    "        for p in train.Patient.values:\n",
    "            self.train_data[p] = os.listdir(f'./Dataset/train/{p}/')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = []\n",
    "        a, tab = [], [] \n",
    "        keys = np.random.choice(self.keys, size = self.batch_size) # randomly chooses n=batch_size number of patients\n",
    "        for k in keys:\n",
    "            try:\n",
    "                i = np.random.choice(self.train_data[k], size=1)[0] # chooses some randomly images for kth patient\n",
    "                img = get_img(f'./Dataset/train/{k}/{i}') # resizes ith image of kth patient\n",
    "                x.append(img) # append kth patient's image data in the list x\n",
    "                a.append(self.a[k]) # append kth patient's gradinet in the list a\n",
    "                tab.append(self.tab[k]) # append kth patient's tabular data in the tab list\n",
    "            except:\n",
    "                print(k, i)\n",
    "       \n",
    "        x,a,tab = np.array(x), np.array(a), np.array(tab) # convert list to array\n",
    "        #x = np.expand_dims(x, axis=-1) \n",
    "        return [x, tab] , a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, shape):\n",
    "    models_dict = {\n",
    "        'b0': efn.EfficientNetB0(input_shape=shape,weights='imagenet',include_top=False),\n",
    "        'b1': efn.EfficientNetB1(input_shape=shape,weights=None,include_top=False),\n",
    "        'b2': efn.EfficientNetB2(input_shape=shape,weights=None,include_top=False),\n",
    "        'b3': efn.EfficientNetB3(input_shape=shape,weights='imagenet',include_top=False),\n",
    "        'b4': efn.EfficientNetB4(input_shape=shape,weights=None,include_top=False),\n",
    "        'b5': efn.EfficientNetB5(input_shape=shape,weights=None,include_top=False),\n",
    "        'b6': efn.EfficientNetB6(input_shape=shape,weights=None,include_top=False),\n",
    "        'b7': efn.EfficientNetB7(input_shape=shape,weights=None,include_top=False),\n",
    "        #'RNet50': resnet50.ResNet50(input_shape=shape,weights=None,include_top=False),\n",
    "        #'V16': vgg16.VGG16(input_shape=shape,weights=None,include_top=False)\n",
    "    }\n",
    "    return models_dict[model]\n",
    "\n",
    "def build_model(shape=(512, 512, 3), model_class=None):\n",
    "    inp = Input(shape=shape)\n",
    "    base = get_model(model_class, shape)\n",
    "    x = base(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    inp2 = Input(shape=(4,)) # indicates that the expected input will be batches of 4-dimensional vectors\n",
    "    x2 = GaussianNoise(0.2)(inp2) # to mitigate overfitting\n",
    "    x = Concatenate()([x, x2]) \n",
    "    x = Dropout(0.5)(x) \n",
    "    x = Dense(1)(x)\n",
    "    model = Model([inp, inp2] , x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " efficientnet-b3 (Functional)   (None, 16, 16, 1536  10783528    ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1536)        0           ['efficientnet-b3[0][0]']        \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " gaussian_noise (GaussianNoise)  (None, 4)           0           ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1540)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'gaussian_noise[0][0]']        \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1540)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            1541        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,785,069\n",
      "Trainable params: 10,697,773\n",
      "Non-trainable params: 87,296\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL_CLASS = 'b3'\n",
    "base_model = build_model(shape=(512, 512, 3), model_class=MODEL_CLASS)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "SAVE_BEST = True\n",
    "tr_p, vl_p = train_test_split(P, shuffle=True, train_size= 0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9494\n",
      "Epoch 1: val_loss improved from inf to 4.87252, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 141s 4s/step - loss: 4.9494 - val_loss: 4.8725 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6354\n",
      "Epoch 2: val_loss improved from 4.87252 to 4.57496, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 118s 4s/step - loss: 4.6354 - val_loss: 4.5750 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1843\n",
      "Epoch 3: val_loss did not improve from 4.57496\n",
      "32/32 [==============================] - 118s 4s/step - loss: 4.1843 - val_loss: 7.4566 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0814\n",
      "Epoch 4: val_loss did not improve from 4.57496\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.0814 - val_loss: 8.4000 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4957\n",
      "Epoch 5: val_loss did not improve from 4.57496\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.4957 - val_loss: 9.2794 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.9730\n",
      "Epoch 6: val_loss improved from 4.57496 to 4.56930, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.9730 - val_loss: 4.5693 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 5.0871\n",
      "Epoch 7: val_loss improved from 4.56930 to 4.49428, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 118s 4s/step - loss: 5.0871 - val_loss: 4.4943 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4114\n",
      "Epoch 8: val_loss improved from 4.49428 to 4.44032, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 118s 4s/step - loss: 4.4114 - val_loss: 4.4403 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3131\n",
      "Epoch 9: val_loss improved from 4.44032 to 4.11308, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 118s 4s/step - loss: 4.3131 - val_loss: 4.1131 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9119\n",
      "Epoch 10: val_loss did not improve from 4.11308\n",
      "32/32 [==============================] - 117s 4s/step - loss: 3.9119 - val_loss: 4.8282 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.6662\n",
      "Epoch 11: val_loss did not improve from 4.11308\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.6662 - val_loss: 4.6758 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8339\n",
      "Epoch 12: val_loss did not improve from 4.11308\n",
      "32/32 [==============================] - 117s 4s/step - loss: 3.8339 - val_loss: 4.5231 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2780\n",
      "Epoch 13: val_loss did not improve from 4.11308\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.2780 - val_loss: 5.2371 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4190\n",
      "Epoch 14: val_loss did not improve from 4.11308\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.4190 - val_loss: 4.3722 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8017\n",
      "Epoch 15: val_loss did not improve from 4.11308\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.8017 - val_loss: 4.3393 - lr: 5.0000e-04\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.5229\n",
      "Epoch 16: val_loss did not improve from 4.11308\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.5229 - val_loss: 4.2051 - lr: 5.0000e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9264\n",
      "Epoch 17: val_loss improved from 4.11308 to 3.88949, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 117s 4s/step - loss: 3.9264 - val_loss: 3.8895 - lr: 5.0000e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2289\n",
      "Epoch 18: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.2289 - val_loss: 3.9237 - lr: 5.0000e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1648\n",
      "Epoch 19: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.1648 - val_loss: 4.6965 - lr: 5.0000e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5293\n",
      "Epoch 20: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.5293 - val_loss: 4.0374 - lr: 5.0000e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7879\n",
      "Epoch 21: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.7879 - val_loss: 4.4869 - lr: 5.0000e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3040\n",
      "Epoch 22: val_loss did not improve from 3.88949\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.3040 - val_loss: 4.2826 - lr: 5.0000e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3317\n",
      "Epoch 23: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.3317 - val_loss: 3.9733 - lr: 2.5000e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8146\n",
      "Epoch 24: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.8146 - val_loss: 4.5152 - lr: 2.5000e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0297\n",
      "Epoch 25: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.0297 - val_loss: 4.7501 - lr: 2.5000e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7736\n",
      "Epoch 26: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.7736 - val_loss: 3.9417 - lr: 2.5000e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.7807\n",
      "Epoch 27: val_loss did not improve from 3.88949\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.7807 - val_loss: 4.1028 - lr: 2.5000e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6007\n",
      "Epoch 28: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.6007 - val_loss: 4.1236 - lr: 1.2500e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1870\n",
      "Epoch 29: val_loss did not improve from 3.88949\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.1870 - val_loss: 4.4042 - lr: 1.2500e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4222\n",
      "Epoch 30: val_loss improved from 3.88949 to 3.64474, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 117s 4s/step - loss: 4.4222 - val_loss: 3.6447 - lr: 1.2500e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3137\n",
      "Epoch 31: val_loss did not improve from 3.64474\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.3137 - val_loss: 3.9263 - lr: 1.2500e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7715\n",
      "Epoch 32: val_loss did not improve from 3.64474\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.7715 - val_loss: 3.9144 - lr: 1.2500e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3493\n",
      "Epoch 33: val_loss did not improve from 3.64474\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.3493 - val_loss: 4.1946 - lr: 1.2500e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.8739\n",
      "Epoch 34: val_loss improved from 3.64474 to 3.64143, saving model to b3_100_epochs.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 116s 4s/step - loss: 4.8739 - val_loss: 3.6414 - lr: 1.2500e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2666\n",
      "Epoch 35: val_loss did not improve from 3.64143\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.2666 - val_loss: 4.4411 - lr: 1.2500e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0636\n",
      "Epoch 36: val_loss did not improve from 3.64143\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.0636 - val_loss: 3.8862 - lr: 1.2500e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8543\n",
      "Epoch 37: val_loss did not improve from 3.64143\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.8543 - val_loss: 5.0297 - lr: 1.2500e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0594\n",
      "Epoch 38: val_loss did not improve from 3.64143\n",
      "32/32 [==============================] - 115s 4s/step - loss: 4.0594 - val_loss: 3.8127 - lr: 1.2500e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0216\n",
      "Epoch 39: val_loss did not improve from 3.64143\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "32/32 [==============================] - 115s 4s/step - loss: 4.0216 - val_loss: 3.7192 - lr: 1.2500e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.3480\n",
      "Epoch 40: val_loss did not improve from 3.64143\n",
      "32/32 [==============================] - 115s 4s/step - loss: 4.3480 - val_loss: 3.6623 - lr: 6.2500e-05\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2557\n",
      "Epoch 41: val_loss did not improve from 3.64143\n",
      "32/32 [==============================] - 115s 4s/step - loss: 4.2557 - val_loss: 3.7209 - lr: 6.2500e-05\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.4711\n",
      "Epoch 42: val_loss improved from 3.64143 to 3.12714, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 115s 4s/step - loss: 4.4711 - val_loss: 3.1271 - lr: 6.2500e-05\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4145\n",
      "Epoch 43: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 114s 4s/step - loss: 3.4145 - val_loss: 3.8283 - lr: 6.2500e-05\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7044\n",
      "Epoch 44: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.7044 - val_loss: 4.0458 - lr: 6.2500e-05\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.9806\n",
      "Epoch 45: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 2.9806 - val_loss: 4.5331 - lr: 6.2500e-05\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9713\n",
      "Epoch 46: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.9713 - val_loss: 4.1194 - lr: 6.2500e-05\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4057\n",
      "Epoch 47: val_loss did not improve from 3.12714\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.4057 - val_loss: 3.9951 - lr: 6.2500e-05\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4445\n",
      "Epoch 48: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.4445 - val_loss: 3.3772 - lr: 3.1250e-05\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2051\n",
      "Epoch 49: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.2051 - val_loss: 3.7172 - lr: 3.1250e-05\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2623\n",
      "Epoch 50: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.2623 - val_loss: 4.0773 - lr: 3.1250e-05\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6096\n",
      "Epoch 51: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.6096 - val_loss: 3.2986 - lr: 3.1250e-05\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1318\n",
      "Epoch 52: val_loss did not improve from 3.12714\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "32/32 [==============================] - 115s 4s/step - loss: 4.1318 - val_loss: 3.2328 - lr: 3.1250e-05\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2848\n",
      "Epoch 53: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 115s 4s/step - loss: 3.2848 - val_loss: 3.5549 - lr: 1.5625e-05\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6775\n",
      "Epoch 54: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.6775 - val_loss: 3.8647 - lr: 1.5625e-05\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2561\n",
      "Epoch 55: val_loss did not improve from 3.12714\n",
      "32/32 [==============================] - 116s 4s/step - loss: 4.2561 - val_loss: 3.6227 - lr: 1.5625e-05\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2318\n",
      "Epoch 56: val_loss improved from 3.12714 to 3.07371, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 117s 4s/step - loss: 3.2318 - val_loss: 3.0737 - lr: 1.5625e-05\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8012\n",
      "Epoch 57: val_loss did not improve from 3.07371\n",
      "32/32 [==============================] - 117s 4s/step - loss: 2.8012 - val_loss: 3.6730 - lr: 1.5625e-05\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9054\n",
      "Epoch 58: val_loss did not improve from 3.07371\n",
      "32/32 [==============================] - 117s 4s/step - loss: 3.9054 - val_loss: 3.1391 - lr: 1.5625e-05\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2347\n",
      "Epoch 59: val_loss did not improve from 3.07371\n",
      "32/32 [==============================] - 118s 4s/step - loss: 3.2347 - val_loss: 3.5710 - lr: 1.5625e-05\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.1251\n",
      "Epoch 60: val_loss did not improve from 3.07371\n",
      "32/32 [==============================] - 118s 4s/step - loss: 3.1251 - val_loss: 3.5433 - lr: 1.5625e-05\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5228\n",
      "Epoch 61: val_loss did not improve from 3.07371\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "32/32 [==============================] - 118s 4s/step - loss: 3.5228 - val_loss: 3.6304 - lr: 1.5625e-05\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7379\n",
      "Epoch 62: val_loss did not improve from 3.07371\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.7379 - val_loss: 3.6813 - lr: 7.8125e-06\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5798\n",
      "Epoch 63: val_loss improved from 3.07371 to 2.74166, saving model to b3_100_epochs.h5\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.5798 - val_loss: 2.7417 - lr: 7.8125e-06\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5729\n",
      "Epoch 64: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.5729 - val_loss: 3.0792 - lr: 7.8125e-06\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2941\n",
      "Epoch 65: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.2941 - val_loss: 3.5271 - lr: 7.8125e-06\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3830\n",
      "Epoch 66: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.3830 - val_loss: 3.2547 - lr: 7.8125e-06\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4383\n",
      "Epoch 67: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.4383 - val_loss: 3.1851 - lr: 7.8125e-06\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 3.6160\n",
      "Epoch 68: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "32/32 [==============================] - 119s 4s/step - loss: 3.6160 - val_loss: 3.2617 - lr: 7.8125e-06\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.2769\n",
      "Epoch 69: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 120s 4s/step - loss: 4.2769 - val_loss: 3.6682 - lr: 3.9063e-06\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2694\n",
      "Epoch 70: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 120s 4s/step - loss: 3.2694 - val_loss: 2.9560 - lr: 3.9063e-06\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0022\n",
      "Epoch 71: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 120s 4s/step - loss: 3.0022 - val_loss: 3.2454 - lr: 3.9063e-06\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.1352\n",
      "Epoch 72: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 120s 4s/step - loss: 4.1352 - val_loss: 3.2602 - lr: 3.9063e-06\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3690\n",
      "Epoch 73: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "32/32 [==============================] - 120s 4s/step - loss: 3.3690 - val_loss: 3.6593 - lr: 3.9063e-06\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4186\n",
      "Epoch 74: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 121s 4s/step - loss: 3.4186 - val_loss: 3.2478 - lr: 1.9531e-06\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2167\n",
      "Epoch 75: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 121s 4s/step - loss: 3.2167 - val_loss: 3.4285 - lr: 1.9531e-06\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.7040\n",
      "Epoch 76: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 120s 4s/step - loss: 3.7040 - val_loss: 3.3728 - lr: 1.9531e-06\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3780\n",
      "Epoch 77: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 121s 4s/step - loss: 3.3780 - val_loss: 3.9970 - lr: 1.9531e-06\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.9992\n",
      "Epoch 78: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "32/32 [==============================] - 121s 4s/step - loss: 2.9992 - val_loss: 3.5734 - lr: 1.9531e-06\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6134\n",
      "Epoch 79: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.6134 - val_loss: 4.1195 - lr: 9.7656e-07\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.2699\n",
      "Epoch 80: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 121s 4s/step - loss: 3.2699 - val_loss: 3.3775 - lr: 9.7656e-07\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5203\n",
      "Epoch 81: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.5203 - val_loss: 3.2376 - lr: 9.7656e-07\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6423\n",
      "Epoch 82: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.6423 - val_loss: 3.3621 - lr: 9.7656e-07\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4234\n",
      "Epoch 83: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.4234 - val_loss: 3.2767 - lr: 9.7656e-07\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8151\n",
      "Epoch 84: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.8151 - val_loss: 3.2156 - lr: 4.8828e-07\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3871\n",
      "Epoch 85: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.3871 - val_loss: 3.6779 - lr: 4.8828e-07\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8148\n",
      "Epoch 86: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 2.8148 - val_loss: 3.3850 - lr: 4.8828e-07\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4639\n",
      "Epoch 87: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.4639 - val_loss: 2.9656 - lr: 4.8828e-07\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.8501\n",
      "Epoch 88: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "32/32 [==============================] - 122s 4s/step - loss: 3.8501 - val_loss: 3.5387 - lr: 4.8828e-07\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 4.0372\n",
      "Epoch 89: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 123s 4s/step - loss: 4.0372 - val_loss: 3.3278 - lr: 2.4414e-07\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4026\n",
      "Epoch 90: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 123s 4s/step - loss: 3.4026 - val_loss: 3.1046 - lr: 2.4414e-07\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.8089\n",
      "Epoch 91: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 123s 4s/step - loss: 2.8089 - val_loss: 3.5673 - lr: 2.4414e-07\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3253\n",
      "Epoch 92: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 123s 4s/step - loss: 3.3253 - val_loss: 3.2516 - lr: 2.4414e-07\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.5796\n",
      "Epoch 93: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "32/32 [==============================] - 123s 4s/step - loss: 3.5796 - val_loss: 3.5421 - lr: 2.4414e-07\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3048\n",
      "Epoch 94: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 123s 4s/step - loss: 3.3048 - val_loss: 3.1624 - lr: 1.2207e-07\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.9737\n",
      "Epoch 95: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 123s 4s/step - loss: 3.9737 - val_loss: 3.1162 - lr: 1.2207e-07\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.0553\n",
      "Epoch 96: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 124s 4s/step - loss: 3.0553 - val_loss: 3.1228 - lr: 1.2207e-07\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 2.6451\n",
      "Epoch 97: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 124s 4s/step - loss: 2.6451 - val_loss: 3.3580 - lr: 1.2207e-07\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.4893\n",
      "Epoch 98: val_loss did not improve from 2.74166\n",
      "\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "32/32 [==============================] - 124s 4s/step - loss: 3.4893 - val_loss: 3.2643 - lr: 1.2207e-07\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.3343\n",
      "Epoch 99: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 124s 4s/step - loss: 3.3343 - val_loss: 3.6383 - lr: 6.1035e-08\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 3.6728\n",
      "Epoch 100: val_loss did not improve from 2.74166\n",
      "32/32 [==============================] - 124s 4s/step - loss: 3.6728 - val_loss: 2.7694 - lr: 6.1035e-08\n",
      "Training Complete!!!\n"
     ]
    }
   ],
   "source": [
    "P = np.array(P)\n",
    "subs = []\n",
    "folds_history = []\n",
    "\n",
    "\"\"\"\n",
    "er = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=1e-3,patience=15,verbose=1,mode=\"auto\",baseline=None,\n",
    "      restore_best_weights=True,) #Stop training when a monitored metric has stopped improving.\n",
    "\"\"\"\n",
    "\n",
    "cpt = tf.keras.callbacks.ModelCheckpoint(filepath=f'{MODEL_CLASS}_{EPOCHS}_epochs.h5',monitor='val_loss',verbose=1, \n",
    "    save_best_only=SAVE_BEST,mode='auto') #to save model or weights in a checkpoint file at lowest validation loss\n",
    "\n",
    "rlp = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5, verbose=1, min_lr=1e-8) \n",
    "     #Reduce learning rate when a metric has stopped improving.\n",
    "     # if improvement stops, after 5 epochs learning rate will be reduced\n",
    "\n",
    "model = build_model(model_class=MODEL_CLASS)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), loss=\"mae\") \n",
    "history = model.fit(IGenerator(keys=tr_p, a = A, tab = TAB, batch_size=BATCH_SIZE), \n",
    "                    steps_per_epoch = 32,\n",
    "                    validation_data=IGenerator(keys=P, a = A, tab = TAB, batch_size=BATCH_SIZE),\n",
    "                    validation_steps = 32, \n",
    "                    callbacks = [cpt, rlp], \n",
    "                    epochs=EPOCHS)\n",
    "folds_history.append(history.history)\n",
    "print('Training Complete!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history.history) \n",
    "\n",
    "# save to json:  \n",
    "hist_json_file = './Saved_Models/EffNet_b3_history_100_epoch_imagenet.json' \n",
    "with open(hist_json_file, mode='w') as f:\n",
    "    hist_df.to_json(f)\n",
    "\n",
    "# or save to csv: \n",
    "hist_csv_file = './Saved_Models/EffNet_b3_history_100_epoch_imagenet.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = './Dataset/train/B2'\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, loss, 'b3', label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, 'b3', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig(result_dir + 'b3_100_epoch_loss_imagenet.png')\n",
    "plt.savefig(result_dir + 'b3_100_epoch_loss_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b3_100_epoch_loss_imagenet.tex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.85):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(20,EPOCHS)\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(loss[20:]), 'b3', label='Training loss')\n",
    "plt.plot(epochs_range,\n",
    "         smooth_curve(val_loss[20:]), 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(result_dir + 'b3_100_epoch_loss_smooth_imagenet.png')\n",
    "plt.savefig(result_dir + 'b3_100_epoch_loss_smooth_imagenet.pdf', dpi=150)\n",
    "tikzplotlib.save(result_dir + 'b3_100_epoch_loss_smooth_imagenet.tex')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(fvc_true, fvc_pred, sigma):\n",
    "    sigma_clip = np.maximum(sigma, 70)\n",
    "    delta = np.abs(fvc_true - fvc_pred)\n",
    "    delta = np.minimum(delta, 1000)\n",
    "    sq2 = np.sqrt(2)\n",
    "    metric = (delta / sigma_clip)*sq2 + np.log(sigma_clip* sq2)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70cc86b0df0414dbc6b8402b4565347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 70s 5s/step\n",
      "2/2 [==============================] - 6s 242ms/step\n",
      "10/10 [==============================] - 52s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "3/3 [==============================] - 11s 3s/step\n",
      "32/32 [==============================] - 154s 5s/step\n",
      "16/16 [==============================] - 71s 4s/step\n",
      "13/13 [==============================] - 57s 4s/step\n",
      "13/13 [==============================] - 62s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "4/4 [==============================] - 20s 5s/step\n",
      "2/2 [==============================] - 10s 4s/step\n",
      "2/2 [==============================] - 6s 909ms/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "2/2 [==============================] - 5s 619ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 88s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 41s 5s/step\n",
      "10/10 [==============================] - 51s 5s/step\n",
      "15/15 [==============================] - 79s 5s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 212ms/step\n",
      "2/2 [==============================] - 5s 213ms/step\n",
      "9/9 [==============================] - 40s 4s/step\n",
      "15/15 [==============================] - 79s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "11/11 [==============================] - 58s 5s/step\n",
      "7/7 [==============================] - 36s 5s/step\n",
      "10/10 [==============================] - 43s 4s/step\n",
      "10/10 [==============================] - 44s 4s/step\n",
      "6.484877462616242\n",
      "13/13 [==============================] - 68s 5s/step\n",
      "2/2 [==============================] - 6s 235ms/step\n",
      "10/10 [==============================] - 54s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "3/3 [==============================] - 11s 3s/step\n",
      "32/32 [==============================] - 150s 5s/step\n",
      "16/16 [==============================] - 67s 4s/step\n",
      "13/13 [==============================] - 54s 4s/step\n",
      "13/13 [==============================] - 57s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "4/4 [==============================] - 16s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 742ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 641ms/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 32s 4s/step\n",
      "10/10 [==============================] - 43s 4s/step\n",
      "15/15 [==============================] - 64s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 4s 212ms/step\n",
      "2/2 [==============================] - 5s 225ms/step\n",
      "9/9 [==============================] - 37s 4s/step\n",
      "15/15 [==============================] - 68s 5s/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "11/11 [==============================] - 51s 5s/step\n",
      "7/7 [==============================] - 29s 4s/step\n",
      "10/10 [==============================] - 43s 4s/step\n",
      "10/10 [==============================] - 42s 4s/step\n",
      "6.486140281572894\n",
      "13/13 [==============================] - 58s 4s/step\n",
      "2/2 [==============================] - 5s 224ms/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "3/3 [==============================] - 10s 3s/step\n",
      "32/32 [==============================] - 136s 4s/step\n",
      "16/16 [==============================] - 66s 4s/step\n",
      "13/13 [==============================] - 53s 4s/step\n",
      "13/13 [==============================] - 57s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "4/4 [==============================] - 16s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 749ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 610ms/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 32s 4s/step\n",
      "10/10 [==============================] - 41s 4s/step\n",
      "15/15 [==============================] - 68s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 231ms/step\n",
      "2/2 [==============================] - 5s 217ms/step\n",
      "9/9 [==============================] - 40s 4s/step\n",
      "15/15 [==============================] - 68s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "11/11 [==============================] - 58s 5s/step\n",
      "7/7 [==============================] - 29s 4s/step\n",
      "10/10 [==============================] - 43s 4s/step\n",
      "10/10 [==============================] - 42s 4s/step\n",
      "6.49264229180511\n",
      "13/13 [==============================] - 58s 4s/step\n",
      "2/2 [==============================] - 5s 201ms/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "32/32 [==============================] - 148s 5s/step\n",
      "16/16 [==============================] - 83s 5s/step\n",
      "13/13 [==============================] - 66s 5s/step\n",
      "13/13 [==============================] - 67s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "4/4 [==============================] - 20s 5s/step\n",
      "2/2 [==============================] - 10s 4s/step\n",
      "2/2 [==============================] - 5s 738ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 612ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 35s 4s/step\n",
      "10/10 [==============================] - 41s 4s/step\n",
      "15/15 [==============================] - 68s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 201ms/step\n",
      "2/2 [==============================] - 5s 201ms/step\n",
      "9/9 [==============================] - 41s 4s/step\n",
      "15/15 [==============================] - 79s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "11/11 [==============================] - 46s 4s/step\n",
      "7/7 [==============================] - 29s 4s/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "10/10 [==============================] - 44s 4s/step\n",
      "6.4998446997048\n",
      "13/13 [==============================] - 62s 5s/step\n",
      "2/2 [==============================] - 5s 214ms/step\n",
      "10/10 [==============================] - 54s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "32/32 [==============================] - 144s 4s/step\n",
      "16/16 [==============================] - 74s 5s/step\n",
      "13/13 [==============================] - 66s 5s/step\n",
      "13/13 [==============================] - 65s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "4/4 [==============================] - 20s 5s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 746ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 622ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 32s 4s/step\n",
      "10/10 [==============================] - 41s 4s/step\n",
      "15/15 [==============================] - 67s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 216ms/step\n",
      "2/2 [==============================] - 5s 203ms/step\n",
      "9/9 [==============================] - 40s 4s/step\n",
      "15/15 [==============================] - 79s 5s/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "11/11 [==============================] - 48s 4s/step\n",
      "7/7 [==============================] - 30s 4s/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "10/10 [==============================] - 44s 4s/step\n",
      "6.5079989030801215\n",
      "13/13 [==============================] - 68s 5s/step\n",
      "2/2 [==============================] - 6s 234ms/step\n",
      "10/10 [==============================] - 53s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "32/32 [==============================] - 147s 5s/step\n",
      "16/16 [==============================] - 83s 5s/step\n",
      "13/13 [==============================] - 66s 5s/step\n",
      "13/13 [==============================] - 67s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "4/4 [==============================] - 20s 5s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 748ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 635ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 32s 4s/step\n",
      "10/10 [==============================] - 42s 4s/step\n",
      "15/15 [==============================] - 67s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 205ms/step\n",
      "2/2 [==============================] - 5s 209ms/step\n",
      "9/9 [==============================] - 42s 5s/step\n",
      "15/15 [==============================] - 79s 5s/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "11/11 [==============================] - 48s 4s/step\n",
      "7/7 [==============================] - 30s 4s/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "10/10 [==============================] - 44s 4s/step\n",
      "6.5216490605721456\n",
      "13/13 [==============================] - 68s 5s/step\n",
      "2/2 [==============================] - 6s 224ms/step\n",
      "10/10 [==============================] - 54s 5s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "32/32 [==============================] - 145s 5s/step\n",
      "16/16 [==============================] - 79s 5s/step\n",
      "13/13 [==============================] - 66s 5s/step\n",
      "13/13 [==============================] - 67s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "4/4 [==============================] - 16s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 761ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 608ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 32s 4s/step\n",
      "10/10 [==============================] - 42s 4s/step\n",
      "15/15 [==============================] - 67s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 198ms/step\n",
      "2/2 [==============================] - 5s 202ms/step\n",
      "9/9 [==============================] - 40s 4s/step\n",
      "15/15 [==============================] - 63s 4s/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "11/11 [==============================] - 50s 5s/step\n",
      "7/7 [==============================] - 30s 4s/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "10/10 [==============================] - 46s 5s/step\n",
      "6.54447538170496\n",
      "13/13 [==============================] - 68s 5s/step\n",
      "2/2 [==============================] - 6s 221ms/step\n",
      "10/10 [==============================] - 54s 5s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "32/32 [==============================] - 153s 5s/step\n",
      "16/16 [==============================] - 84s 5s/step\n",
      "13/13 [==============================] - 66s 5s/step\n",
      "13/13 [==============================] - 67s 5s/step\n",
      "2/2 [==============================] - 10s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "4/4 [==============================] - 16s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 745ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 622ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 81s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 32s 4s/step\n",
      "10/10 [==============================] - 42s 4s/step\n",
      "15/15 [==============================] - 67s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "2/2 [==============================] - 5s 206ms/step\n",
      "2/2 [==============================] - 5s 204ms/step\n",
      "9/9 [==============================] - 37s 4s/step\n",
      "15/15 [==============================] - 67s 4s/step\n",
      "2/2 [==============================] - 7s 3s/step\n",
      "11/11 [==============================] - 50s 4s/step\n",
      "7/7 [==============================] - 32s 5s/step\n",
      "10/10 [==============================] - 54s 5s/step\n",
      "10/10 [==============================] - 51s 5s/step\n",
      "6.57499529094197\n",
      "13/13 [==============================] - 65s 5s/step\n",
      "2/2 [==============================] - 6s 230ms/step\n",
      "10/10 [==============================] - 43s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "3/3 [==============================] - 9s 2s/step\n",
      "32/32 [==============================] - 150s 5s/step\n",
      "16/16 [==============================] - 83s 5s/step\n",
      "13/13 [==============================] - 66s 5s/step\n",
      "13/13 [==============================] - 63s 5s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "4/4 [==============================] - 16s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 769ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "2/2 [==============================] - 5s 613ms/step\n",
      "2/2 [==============================] - 8s 3s/step\n",
      "19/19 [==============================] - 78s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 36s 4s/step\n",
      "10/10 [==============================] - 45s 4s/step\n",
      "15/15 [==============================] - 79s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "2/2 [==============================] - 6s 226ms/step\n",
      "2/2 [==============================] - 6s 233ms/step\n",
      "9/9 [==============================] - 40s 4s/step\n",
      "15/15 [==============================] - 76s 5s/step\n",
      "2/2 [==============================] - 9s 4s/step\n",
      "11/11 [==============================] - 58s 5s/step\n",
      "7/7 [==============================] - 36s 5s/step\n",
      "10/10 [==============================] - 49s 5s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 46s 5s/step\n",
      "6.6267244981866265\n"
     ]
    }
   ],
   "source": [
    "metric = []\n",
    "for q in tqdm(range(1, 10)):\n",
    "    m = []\n",
    "    for p in vl_p:\n",
    "        x = [] \n",
    "        tab = [] \n",
    "        \n",
    "        if p in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n",
    "            continue\n",
    "        for i in os.listdir(f'./Dataset/train/{p}/'):\n",
    "            x.append(get_img(f'./Dataset/train/{p}/{i}')) \n",
    "            tab.append(get_tab(train.loc[train.Patient == p, :])) \n",
    "        tab = np.array(tab) \n",
    "    \n",
    "        x = np.expand_dims(x, axis=-1) \n",
    "        _a = model.predict([x, tab]) \n",
    "        a = np.quantile(_a, q / 10)\n",
    "        \n",
    "        percent_true = train.Percent.values[train.Patient == p]\n",
    "        fvc_true = train.FVC.values[train.Patient == p]\n",
    "        weeks_true = train.Weeks.values[train.Patient == p]\n",
    "        \n",
    "        fvc = a * (weeks_true - weeks_true[0]) + fvc_true[0]\n",
    "        percent = percent_true[0] - a * abs(weeks_true - weeks_true[0])\n",
    "        m.append(score(fvc_true, fvc, percent))\n",
    "    print(np.mean(m))\n",
    "    metric.append(np.mean(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = (np.argmin(metric) + 1)/ 2\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week   FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  2000         100\n",
       "1  ID00421637202311550012437_-12  2000         100\n",
       "2  ID00422637202311677017371_-12  2000         100\n",
       "3  ID00423637202312137826377_-12  2000         100\n",
       "4  ID00426637202313170790466_-12  2000         100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('./Dataset/sample_submission.csv') \n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Weeks</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SmokingStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264</td>\n",
       "      <td>6</td>\n",
       "      <td>3020</td>\n",
       "      <td>70.186855</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437</td>\n",
       "      <td>15</td>\n",
       "      <td>2739</td>\n",
       "      <td>82.045291</td>\n",
       "      <td>68</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371</td>\n",
       "      <td>6</td>\n",
       "      <td>1930</td>\n",
       "      <td>76.672493</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377</td>\n",
       "      <td>17</td>\n",
       "      <td>3294</td>\n",
       "      <td>79.258903</td>\n",
       "      <td>72</td>\n",
       "      <td>Male</td>\n",
       "      <td>Ex-smoker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466</td>\n",
       "      <td>0</td>\n",
       "      <td>2925</td>\n",
       "      <td>71.824968</td>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Never smoked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Patient  Weeks   FVC    Percent  Age   Sex SmokingStatus\n",
       "0  ID00419637202311204720264      6  3020  70.186855   73  Male     Ex-smoker\n",
       "1  ID00421637202311550012437     15  2739  82.045291   68  Male     Ex-smoker\n",
       "2  ID00422637202311677017371      6  1930  76.672493   73  Male     Ex-smoker\n",
       "3  ID00423637202312137826377     17  3294  79.258903   72  Male     Ex-smoker\n",
       "4  ID00426637202313170790466      0  2925  71.824968   73  Male  Never smoked"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('./Dataset/test.csv') \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "2/2 [==============================] - 8s 4s/step\n",
      "15/15 [==============================] - 69s 5s/step\n",
      "10/10 [==============================] - 48s 5s/step\n",
      "13/13 [==============================] - 69s 5s/step\n"
     ]
    }
   ],
   "source": [
    "A_test, B_test, P_test, W, FVC, STD, WEEK = {},{},{},{},{},{},{} \n",
    "\n",
    "for p in test.Patient.unique():\n",
    "    x = [] \n",
    "    tab = [] \n",
    "    for i in os.listdir(f'./Dataset/test/{p}/'):\n",
    "        x.append(get_img(f'./Dataset/test/{p}/{i}')) \n",
    "        tab.append(get_tab(test.loc[test.Patient == p, :])) \n",
    "    tab = np.array(tab) \n",
    "            \n",
    "    x = np.expand_dims(x, axis=-1) \n",
    "    _a = model.predict([x, tab]) \n",
    "    a = np.quantile(_a, q)\n",
    "    A_test[p] = a\n",
    "    B_test[p] = test.FVC.values[test.Patient == p] - a*test.Weeks.values[test.Patient == p]\n",
    "    P_test[p] = test.Percent.values[test.Patient == p] \n",
    "    WEEK[p] = test.Weeks.values[test.Patient == p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sub.Patient_Week.values:\n",
    "    p, w = k.split('_')\n",
    "    w = int(w) \n",
    "    \n",
    "    fvc = A_test[p] * w + B_test[p]\n",
    "    sub.loc[sub.Patient_Week == k, 'FVC'] = fvc\n",
    "    sub.loc[sub.Patient_Week == k, 'Confidence'] = (\n",
    "        P_test[p] - A_test[p] * abs(WEEK[p] - w) \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Week</th>\n",
       "      <th>FVC</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID00419637202311204720264_-12</td>\n",
       "      <td>3054.293030</td>\n",
       "      <td>104.479885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID00421637202311550012437_-12</td>\n",
       "      <td>2819.521416</td>\n",
       "      <td>162.566707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID00422637202311677017371_-12</td>\n",
       "      <td>1967.108448</td>\n",
       "      <td>113.780941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID00423637202312137826377_-12</td>\n",
       "      <td>3472.876736</td>\n",
       "      <td>258.135638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID00426637202313170790466_-12</td>\n",
       "      <td>2964.619885</td>\n",
       "      <td>111.444853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patient_Week          FVC  Confidence\n",
       "0  ID00419637202311204720264_-12  3054.293030  104.479885\n",
       "1  ID00421637202311550012437_-12  2819.521416  162.566707\n",
       "2  ID00422637202311677017371_-12  1967.108448  113.780941\n",
       "3  ID00423637202312137826377_-12  3472.876736  258.135638\n",
       "4  ID00426637202313170790466_-12  2964.619885  111.444853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[[\"Patient_Week\",\"FVC\",\"Confidence\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add infos\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"./Dataset/\"\n",
    "BATCH_SIZE=128\n",
    "\n",
    "tr = pd.read_csv(f\"{ROOT}/train.csv\")\n",
    "tr.drop_duplicates(keep=False, inplace=True, subset=['Patient','Weeks'])\n",
    "chunk = pd.read_csv(f\"{ROOT}/test.csv\")\n",
    "\n",
    "print(\"add infos\")\n",
    "sub = pd.read_csv(f\"{ROOT}/sample_submission.csv\")\n",
    "sub['Patient'] = sub['Patient_Week'].apply(lambda x:x.split('_')[0])\n",
    "sub['Weeks'] = sub['Patient_Week'].apply(lambda x: int(x.split('_')[-1]))\n",
    "sub =  sub[['Patient','Weeks','Confidence','Patient_Week']]\n",
    "sub = sub.merge(chunk.drop('Weeks', axis=1), on=\"Patient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr['WHERE'] = 'train'\n",
    "chunk['WHERE'] = 'val'\n",
    "sub['WHERE'] = 'test'\n",
    "data = tr.append([chunk, sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1535, 8) (5, 8) (730, 10) (2270, 10)\n",
      "176 5 5 176\n"
     ]
    }
   ],
   "source": [
    "print(tr.shape, chunk.shape, sub.shape, data.shape)\n",
    "print(tr.Patient.nunique(), chunk.Patient.nunique(), sub.Patient.nunique(), \n",
    "      data.Patient.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['min_week'] = data['Weeks']\n",
    "data.loc[data.WHERE=='test','min_week'] = np.nan\n",
    "data['min_week'] = data.groupby('Patient')['min_week'].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data.loc[data.Weeks == data.min_week]\n",
    "base = base[['Patient','FVC']].copy()\n",
    "base.columns = ['Patient','min_FVC']\n",
    "base['nb'] = 1\n",
    "base['nb'] = base.groupby('Patient')['nb'].transform('cumsum')\n",
    "base = base[base.nb==1]\n",
    "base.drop('nb', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(base, on='Patient', how='left')\n",
    "data['base_week'] = data['Weeks'] - data['min_week']\n",
    "del base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = ['Sex','SmokingStatus'] #,'Age'\n",
    "FE = []\n",
    "for col in COLS:\n",
    "    for mod in data[col].unique():\n",
    "        FE.append(mod)\n",
    "        data[mod] = (data[col] == mod).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = (data['Age'] - data['Age'].min() ) / ( data['Age'].max() - data['Age'].min() )\n",
    "data['BASE'] = (data['min_FVC'] - data['min_FVC'].min() ) / ( data['min_FVC'].max() - data['min_FVC'].min() )\n",
    "data['week'] = (data['base_week'] - data['base_week'].min() ) / ( data['base_week'].max() - data['base_week'].min() )\n",
    "data['percent'] = (data['Percent'] - data['Percent'].min() ) / ( data['Percent'].max() - data['Percent'].min() )\n",
    "FE += ['age','percent','week','BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = data.loc[data.WHERE=='train']\n",
    "chunk = data.loc[data.WHERE=='val']\n",
    "sub = data.loc[data.WHERE=='test']\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1535, 22), (5, 22), (730, 22))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.shape, chunk.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, C2 = tf.constant(70, dtype='float32'), tf.constant(1000, dtype=\"float32\")\n",
    "def score(y_true, y_pred):\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "    sigma = y_pred[:, 2] - y_pred[:, 0]\n",
    "    fvc_pred = y_pred[:, 1]\n",
    "    \n",
    "    sigma_clip = tf.maximum(sigma, C1)\n",
    "    delta = tf.abs(y_true[:, 0] - fvc_pred)\n",
    "    delta = tf.minimum(delta, C2)\n",
    "    sq2 = tf.sqrt( tf.dtypes.cast(2, dtype=tf.float32) )\n",
    "    metric = (delta / sigma_clip)*sq2 + tf.math.log(sigma_clip* sq2)\n",
    "    return K.mean(metric)\n",
    "\n",
    "def qloss(y_true, y_pred):\n",
    "    qs = [0.2, 0.50, 0.8]\n",
    "    q = tf.constant(np.array([qs]), dtype=tf.float32)\n",
    "    e = y_true - y_pred\n",
    "    v = tf.maximum(q*e, (q-1)*e)\n",
    "    return K.mean(v)\n",
    "\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        return _lambda * qloss(y_true, y_pred) + (1 - _lambda)*score(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def laplace_log_likelihood(actual_fvc, predicted_fvc, confidence, return_values = False):\n",
    "    \"\"\"\n",
    "    Calculates the modified Laplace Log Likelihood score for this competition.\n",
    "    \"\"\"\n",
    "    sd_clipped = np.maximum(confidence, 70)\n",
    "    delta = np.minimum(np.abs(actual_fvc - predicted_fvc), 1000)\n",
    "    metric = - np.sqrt(2) * delta / sd_clipped - np.log(np.sqrt(2) * sd_clipped)\n",
    "\n",
    "    if return_values:\n",
    "        return metric\n",
    "    else:\n",
    "        return np.mean(metric)\n",
    "\n",
    "def make_model(nh):\n",
    "    z = L.Input((nh,), name=\"Patient\")\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d1\")(z)\n",
    "    x = L.Dense(100, activation=\"relu\", name=\"d2\")(x)\n",
    "    p1 = L.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
    "    p2 = L.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
    "    preds = L.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                     name=\"preds\")([p1, p2])\n",
    "    \n",
    "    model = M.Model(z, preds, name=\"CNN\")\n",
    "    #model.compile(loss=qloss, optimizer=\"adam\", metrics=[score])\n",
    "    model.compile(loss=mloss(0.8), optimizer=tf.keras.optimizers.legacy.Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False), metrics=[score])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GET TRAINING DATA AND TARGET VALUE\n",
    "\n",
    "# get target value\n",
    "y  = tr['FVC'].values\n",
    "\n",
    "# get training & test data\n",
    "X_train = tr[FE].values\n",
    "X_test = sub[FE].values\n",
    "\n",
    "\n",
    "nh = X_train.shape[1]\n",
    "\n",
    "# instantiate target arrays\n",
    "train_preds = np.zeros((X_train.shape[0], 3))\n",
    "test_preds = np.zeros((X_test.shape[0], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Patient (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " d1 (Dense)                     (None, 100)          1000        ['Patient[0][0]']                \n",
      "                                                                                                  \n",
      " d2 (Dense)                     (None, 100)          10100       ['d1[0][0]']                     \n",
      "                                                                                                  \n",
      " p1 (Dense)                     (None, 3)            303         ['d2[0][0]']                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " p2 (Dense)                     (None, 3)            303         ['d2[0][0]']                     \n",
      "                                                                                                  \n",
      " preds (Lambda)                 (None, 3)            0           ['p1[0][0]',                     \n",
      "                                                                  'p2[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,706\n",
      "Trainable params: 11,706\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "11706\n"
     ]
    }
   ],
   "source": [
    "net = make_model(nh)\n",
    "print(net.summary())\n",
    "print(net.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2315., 2214., 2061., ..., 2908., 2975., 2774.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [40.035430908203125, 6.490445613861084]\n",
      "val [41.691139221191406, 6.566389560699463]\n",
      "predict test...\n",
      "FOLD 2\n",
      "train [35.58421325683594, 6.377707004547119]\n",
      "val [55.437747955322266, 6.852546691894531]\n",
      "predict test...\n",
      "FOLD 3\n",
      "train [40.55365753173828, 6.535275459289551]\n",
      "val [54.5087890625, 7.092729091644287]\n",
      "predict test...\n",
      "FOLD 4\n",
      "train [40.394142150878906, 6.525821685791016]\n",
      "val [47.86277770996094, 6.63870096206665]\n",
      "predict test...\n",
      "FOLD 5\n",
      "train [41.91270446777344, 6.551510810852051]\n",
      "val [44.426090240478516, 6.587849140167236]\n",
      "predict test...\n"
     ]
    }
   ],
   "source": [
    "model_cnt = 1\n",
    "# instantiate target arrays\n",
    "globals()['train_preds_{}'.format(model_cnt)] = np.zeros((X_train.shape[0], 3))\n",
    "globals()['test_preds_{}'.format(model_cnt)] = np.zeros((X_test.shape[0], 3))\n",
    "\n",
    "NFOLD = 5\n",
    "gkf = GroupKFold(n_splits=NFOLD)\n",
    "groups = tr['Patient'].values\n",
    "\n",
    "cnt = 0\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE=128\n",
    "\n",
    "for tr_idx, val_idx in gkf.split(X_train,y, groups):\n",
    "    cnt += 1\n",
    "    print(f\"FOLD {cnt}\")\n",
    "    net = make_model(nh)\n",
    "    net.fit(X_train[tr_idx], y[tr_idx], batch_size=BATCH_SIZE, epochs=EPOCHS,validation_data=(X_train[val_idx], y[val_idx]), verbose=0) #\n",
    "    print(\"train\", net.evaluate(X_train[tr_idx], y[tr_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "    print(\"val\", net.evaluate(X_train[val_idx], y[val_idx], verbose=0, batch_size=BATCH_SIZE))\n",
    "        #print(\"predict val...\")\n",
    "    globals()['train_preds_{}'.format(model_cnt)][val_idx] = net.predict(X_train[val_idx], batch_size=BATCH_SIZE, verbose=0)\n",
    "    print(\"predict test...\")\n",
    "    globals()['test_preds_{}'.format(model_cnt)] += net.predict(X_test, batch_size=BATCH_SIZE, verbose=0) / NFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Score:  -6.69266798412239\n"
     ]
    }
   ],
   "source": [
    "predicted_fvc = globals()['train_preds_{}'.format(model_cnt)][:,1]\n",
    "confidence = globals()['train_preds_{}'.format(model_cnt)][:,2]-globals()['train_preds_{}'.format(model_cnt)][:,0]\n",
    "model_score = laplace_log_likelihood(actual_fvc = y, predicted_fvc = predicted_fvc, confidence = confidence,\n",
    "                       return_values = False)\n",
    "print('Overall Score: ', model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
